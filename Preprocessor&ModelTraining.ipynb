{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c5c7cef",
   "metadata": {},
   "source": [
    "# Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9f6001df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "25bd1a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "df = []\n",
    "df = pd.read_csv('new_data_set_all_indicator.csv')\n",
    "# Optional: display the first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "06e5dc76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Prev_Open</th>\n",
       "      <th>Prev_Close</th>\n",
       "      <th>...</th>\n",
       "      <th>MACDs_12_26_9</th>\n",
       "      <th>rsi</th>\n",
       "      <th>BBL_3_2.0</th>\n",
       "      <th>BBM_3_2.0</th>\n",
       "      <th>BBU_3_2.0</th>\n",
       "      <th>BBB_3_2.0</th>\n",
       "      <th>BBP_3_2.0</th>\n",
       "      <th>atr</th>\n",
       "      <th>obv</th>\n",
       "      <th>vwap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1980-12-12</td>\n",
       "      <td>0.098834</td>\n",
       "      <td>0.099264</td>\n",
       "      <td>0.098834</td>\n",
       "      <td>0.098834</td>\n",
       "      <td>469033600</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>469033600.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1980-12-15</td>\n",
       "      <td>0.093678</td>\n",
       "      <td>0.094108</td>\n",
       "      <td>0.093678</td>\n",
       "      <td>0.094108</td>\n",
       "      <td>175884800</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.098834</td>\n",
       "      <td>0.098834</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>293148800.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1980-12-16</td>\n",
       "      <td>0.086802</td>\n",
       "      <td>0.087232</td>\n",
       "      <td>0.086802</td>\n",
       "      <td>0.087232</td>\n",
       "      <td>105728000</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.094108</td>\n",
       "      <td>0.093678</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.083248</td>\n",
       "      <td>0.093105</td>\n",
       "      <td>0.102962</td>\n",
       "      <td>21.174900</td>\n",
       "      <td>0.180314</td>\n",
       "      <td>NaN</td>\n",
       "      <td>187420800.0</td>\n",
       "      <td>0.096075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1980-12-17</td>\n",
       "      <td>0.088951</td>\n",
       "      <td>0.089381</td>\n",
       "      <td>0.088951</td>\n",
       "      <td>0.088951</td>\n",
       "      <td>86441600</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.087232</td>\n",
       "      <td>0.086802</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.808075</td>\n",
       "      <td>0.084066</td>\n",
       "      <td>0.089811</td>\n",
       "      <td>0.095555</td>\n",
       "      <td>12.791741</td>\n",
       "      <td>0.425172</td>\n",
       "      <td>0.004478</td>\n",
       "      <td>273862400.0</td>\n",
       "      <td>0.090736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1980-12-18</td>\n",
       "      <td>0.091530</td>\n",
       "      <td>0.091959</td>\n",
       "      <td>0.091530</td>\n",
       "      <td>0.091530</td>\n",
       "      <td>73449600</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>0.088951</td>\n",
       "      <td>0.088951</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.669571</td>\n",
       "      <td>0.085229</td>\n",
       "      <td>0.089094</td>\n",
       "      <td>0.092960</td>\n",
       "      <td>8.676562</td>\n",
       "      <td>0.815045</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>347312000.0</td>\n",
       "      <td>0.088952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        Date     Close      High       Low      Open     Volume  \\\n",
       "0           0  1980-12-12  0.098834  0.099264  0.098834  0.098834  469033600   \n",
       "1           1  1980-12-15  0.093678  0.094108  0.093678  0.094108  175884800   \n",
       "2           2  1980-12-16  0.086802  0.087232  0.086802  0.087232  105728000   \n",
       "3           3  1980-12-17  0.088951  0.089381  0.088951  0.088951   86441600   \n",
       "4           4  1980-12-18  0.091530  0.091959  0.091530  0.091530   73449600   \n",
       "\n",
       "  Symbol  Prev_Open  Prev_Close  ...  MACDs_12_26_9        rsi  BBL_3_2.0  \\\n",
       "0   AAPL        NaN         NaN  ...            NaN        NaN        NaN   \n",
       "1   AAPL   0.098834    0.098834  ...            NaN        NaN        NaN   \n",
       "2   AAPL   0.094108    0.093678  ...            NaN        NaN   0.083248   \n",
       "3   AAPL   0.087232    0.086802  ...            NaN  23.808075   0.084066   \n",
       "4   AAPL   0.088951    0.088951  ...            NaN  46.669571   0.085229   \n",
       "\n",
       "   BBM_3_2.0  BBU_3_2.0  BBB_3_2.0  BBP_3_2.0       atr          obv      vwap  \n",
       "0        NaN        NaN        NaN        NaN       NaN  469033600.0       NaN  \n",
       "1        NaN        NaN        NaN        NaN       NaN  293148800.0       NaN  \n",
       "2   0.093105   0.102962  21.174900   0.180314       NaN  187420800.0  0.096075  \n",
       "3   0.089811   0.095555  12.791741   0.425172  0.004478  273862400.0  0.090736  \n",
       "4   0.089094   0.092960   8.676562   0.815045  0.003868  347312000.0  0.088952  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c2645047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1964328 entries, 0 to 1964327\n",
      "Data columns (total 31 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   Unnamed: 0         int64  \n",
      " 1   Date               object \n",
      " 2   Close              float64\n",
      " 3   High               float64\n",
      " 4   Low                float64\n",
      " 5   Open               float64\n",
      " 6   Volume             int64  \n",
      " 7   Symbol             object \n",
      " 8   Prev_Open          float64\n",
      " 9   Prev_Close         float64\n",
      " 10  Doji               bool   \n",
      " 11  Hammer             bool   \n",
      " 12  Shooting_Star      bool   \n",
      " 13  Bullish_Engulfing  bool   \n",
      " 14  Bearish_Engulfing  bool   \n",
      " 15  Sector             object \n",
      " 16  ema_12             float64\n",
      " 17  ema_26             float64\n",
      " 18  ema_short          float64\n",
      " 19  MACD_12_26_9       float64\n",
      " 20  MACDh_12_26_9      float64\n",
      " 21  MACDs_12_26_9      float64\n",
      " 22  rsi                float64\n",
      " 23  BBL_3_2.0          float64\n",
      " 24  BBM_3_2.0          float64\n",
      " 25  BBU_3_2.0          float64\n",
      " 26  BBB_3_2.0          float64\n",
      " 27  BBP_3_2.0          float64\n",
      " 28  atr                float64\n",
      " 29  obv                float64\n",
      " 30  vwap               float64\n",
      "dtypes: bool(5), float64(21), int64(2), object(3)\n",
      "memory usage: 399.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebaefb0c",
   "metadata": {},
   "source": [
    "# Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "61f00b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fa1f1cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(df, numerical_cols):\n",
    "    \"\"\"Normalize numerical columns to [0, 1] range.\"\"\"\n",
    "    scaler = MinMaxScaler()\n",
    "    df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n",
    "    return df\n",
    "\n",
    "# Example usage:\n",
    "# numerical_cols = ['Close', 'rsi', 'MACD_12_26_9', ...]\n",
    "# df = normalize_features(df, numerical_cols)\n",
    "def encode_categorical(df, categorical_cols):\n",
    "    \"\"\"One-hot encode categorical columns (e.g., Sector).\"\"\"\n",
    "    encoder = OneHotEncoder(sparse=False)  # Use `sparse=False` for older scikit-learn\n",
    "    encoded = encoder.fit_transform(df[categorical_cols])\n",
    "    encoded_df = pd.DataFrame(encoded, columns=encoder.get_feature_names(categorical_cols))\n",
    "    return pd.concat([df.drop(categorical_cols, axis=1), encoded_df], axis=1)\n",
    "\n",
    "# Example usage:\n",
    "# categorical_cols = ['Sector', 'Doji', 'Hammer', ...]\n",
    "# df = encode_categorical(df, categorical_cols)\n",
    "\n",
    "def create_target(df, window=3, threshold=0.01):\n",
    "    \"\"\"Create binary target: 1 if price rises > threshold in next `window` days.\"\"\"\n",
    "    df['future_close'] = df.groupby('Symbol')['Close'].shift(-window)\n",
    "    df['target'] = (df['future_close'] > df['Close'] * (1 + threshold)).astype(int)\n",
    "    return df.dropna(subset=['target'])\n",
    "\n",
    "# Example usage:\n",
    "# df = create_target(df, window=3, threshold=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92df3e9b",
   "metadata": {},
   "source": [
    "# Image Conversion Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c67564f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ohlc_channel(df_group, window=3):\n",
    "    \"\"\"Convert OHLC data to a 4xW matrix (channel 1).\"\"\"\n",
    "    ohlc = df_group[['Open', 'High', 'Low', 'Close']].values.T  # Shape: (4, W)\n",
    "    return ohlc\n",
    "\n",
    "def create_indicator_channel(df_group, window=3, indicators=['rsi', 'MACD_12_26_9']):\n",
    "    \"\"\"Convert indicators to a NxW matrix (channel 2).\"\"\"\n",
    "    indicator_data = df_group[indicators].values.T  # Shape: (N_indicators, W)\n",
    "    return indicator_data\n",
    "\n",
    "def tabular_to_image(df, window=3):\n",
    "    \"\"\"Convert each sample to a multi-channel image.\"\"\"\n",
    "    images, tabular_data = [], []\n",
    "    symbols = df['Symbol'].unique()\n",
    "    symbolCount = 0\n",
    "    for symbol in symbols:\n",
    "        symbolCount = symbolCount + 1\n",
    "        print(\"PROCESSING: {} - {} of {} symbols...\".format(symbol, symbolCount, len(symbols)))\n",
    "        symbol_df = df[df['Symbol'] == symbol].reset_index(drop=True)\n",
    "        print(\"Records in this Symbol: {}...\".format(len(symbol_df) - window + 1))     \n",
    "        for i in range(len(symbol_df) - window + 1):\n",
    "            # Channel 1: OHLC\n",
    "            ohlc = create_ohlc_channel(symbol_df.iloc[i:i+window])\n",
    "            # Channel 2: Indicators\n",
    "            indicators = create_indicator_channel(symbol_df.iloc[i:i+window])\n",
    "            # Combine channels\n",
    "            img = np.vstack([ohlc, indicators])  # Shape: (4 + N_indicators, W)\n",
    "            images.append(img[..., np.newaxis])  # Add channel dim\n",
    "            # Tabular features (e.g., Volume, Sector)\n",
    "            tabular_data.append(symbol_df.iloc[i][['Volume', 'obv']].values)\n",
    "    \n",
    "    return np.array(images), np.array(tabular_data)  # Shapes: (B, H, W, 1), (B, N_tabular)\n",
    "\n",
    "# Example usage:\n",
    "# images, tabular_data = tabular_to_image(df, window=3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edaa380",
   "metadata": {},
   "source": [
    "# Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "132b15a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Concatenate, Dropout\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d7f7f6",
   "metadata": {},
   "source": [
    "# RUNNER - Driver Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9833d78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline\n",
    "numerical_cols = [\n",
    "    'Close', 'High', 'Low', 'Open', 'Volume', 'Prev_Open', 'Prev_Close',\n",
    "    'ema_12', 'ema_26', 'ema_short', 'MACD_12_26_9', 'MACDh_12_26_9', 'MACDs_12_26_9',\n",
    "    'rsi', 'BBL_3_2.0', 'BBM_3_2.0', 'BBU_3_2.0', 'BBB_3_2.0', 'BBP_3_2.0',\n",
    "    'atr', 'obv', 'vwap'\n",
    "]\n",
    "\n",
    "categorical_cols = [\n",
    "    'Sector',  # Object type\n",
    "    'Doji', 'Hammer', 'Shooting_Star', 'Bullish_Engulfing', 'Bearish_Engulfing'  # Boolean flags\n",
    "]\n",
    "\n",
    "df = normalize_features(df, numerical_cols)\n",
    "df = encode_categorical(df, categorical_cols)\n",
    "df = create_target(df, window=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "69dccff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING: AAPL - 1 of 220 symbols...\n",
      "Records in this Symbol: 11100...\n",
      "PROCESSING: ABBV - 2 of 220 symbols...\n",
      "Records in this Symbol: 3015...\n",
      "PROCESSING: ABT - 3 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: ACN - 4 of 220 symbols...\n",
      "Records in this Symbol: 5895...\n",
      "PROCESSING: ADBE - 5 of 220 symbols...\n",
      "Records in this Symbol: 9668...\n",
      "PROCESSING: ADI - 6 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: ADM - 7 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: ADP - 8 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: AEP - 9 of 220 symbols...\n",
      "Records in this Symbol: 15853...\n",
      "PROCESSING: AIG - 10 of 220 symbols...\n",
      "Records in this Symbol: 13108...\n",
      "PROCESSING: ALGN - 11 of 220 symbols...\n",
      "Records in this Symbol: 6013...\n",
      "PROCESSING: AMAT - 12 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: AMD - 13 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: AMGN - 14 of 220 symbols...\n",
      "Records in this Symbol: 10465...\n",
      "PROCESSING: AMT - 15 of 220 symbols...\n",
      "Records in this Symbol: 6750...\n",
      "PROCESSING: AMZN - 16 of 220 symbols...\n",
      "Records in this Symbol: 6948...\n",
      "PROCESSING: ANET - 17 of 220 symbols...\n",
      "Records in this Symbol: 2656...\n",
      "PROCESSING: AON - 18 of 220 symbols...\n",
      "Records in this Symbol: 11235...\n",
      "PROCESSING: APD - 19 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: ASML - 20 of 220 symbols...\n",
      "Records in this Symbol: 7497...\n",
      "PROCESSING: AVGO - 21 of 220 symbols...\n",
      "Records in this Symbol: 3872...\n",
      "PROCESSING: AXON - 22 of 220 symbols...\n",
      "Records in this Symbol: 5916...\n",
      "PROCESSING: AXP - 23 of 220 symbols...\n",
      "Records in this Symbol: 13254...\n",
      "PROCESSING: AZO - 24 of 220 symbols...\n",
      "Records in this Symbol: 8497...\n",
      "PROCESSING: BABA - 25 of 220 symbols...\n",
      "Records in this Symbol: 2583...\n",
      "PROCESSING: BAX - 26 of 220 symbols...\n",
      "Records in this Symbol: 10880...\n",
      "PROCESSING: BA - 27 of 220 symbols...\n",
      "Records in this Symbol: 15853...\n",
      "PROCESSING: BBY - 28 of 220 symbols...\n",
      "Records in this Symbol: 10001...\n",
      "PROCESSING: BIDU - 29 of 220 symbols...\n",
      "Records in this Symbol: 4879...\n",
      "PROCESSING: BIIB - 30 of 220 symbols...\n",
      "Records in this Symbol: 8380...\n",
      "PROCESSING: BLK - 31 of 220 symbols...\n",
      "Records in this Symbol: 6348...\n",
      "PROCESSING: BMY - 32 of 220 symbols...\n",
      "Records in this Symbol: 13254...\n",
      "PROCESSING: CAT - 33 of 220 symbols...\n",
      "Records in this Symbol: 15853...\n",
      "PROCESSING: CB - 34 of 220 symbols...\n",
      "Records in this Symbol: 7995...\n",
      "PROCESSING: CCL - 35 of 220 symbols...\n",
      "Records in this Symbol: 9429...\n",
      "PROCESSING: CDW - 36 of 220 symbols...\n",
      "Records in this Symbol: 2893...\n",
      "PROCESSING: CGC - 37 of 220 symbols...\n",
      "Records in this Symbol: 2698...\n",
      "PROCESSING: CGNX - 38 of 220 symbols...\n",
      "Records in this Symbol: 8926...\n",
      "PROCESSING: CHKP - 39 of 220 symbols...\n",
      "Records in this Symbol: 7170...\n",
      "PROCESSING: CHTR - 40 of 220 symbols...\n",
      "Records in this Symbol: 3768...\n",
      "PROCESSING: CI - 41 of 220 symbols...\n",
      "Records in this Symbol: 10773...\n",
      "PROCESSING: CLX - 42 of 220 symbols...\n",
      "Records in this Symbol: 13074...\n",
      "PROCESSING: CL - 43 of 220 symbols...\n",
      "Records in this Symbol: 13025...\n",
      "PROCESSING: CME - 44 of 220 symbols...\n",
      "Records in this Symbol: 5549...\n",
      "PROCESSING: CNC - 45 of 220 symbols...\n",
      "Records in this Symbol: 5796...\n",
      "PROCESSING: COF - 46 of 220 symbols...\n",
      "Records in this Symbol: 7578...\n",
      "PROCESSING: COP - 47 of 220 symbols...\n",
      "Records in this Symbol: 10835...\n",
      "PROCESSING: COST - 48 of 220 symbols...\n",
      "Records in this Symbol: 9693...\n",
      "PROCESSING: CRM - 49 of 220 symbols...\n",
      "Records in this Symbol: 5162...\n",
      "PROCESSING: CRWD - 50 of 220 symbols...\n",
      "Records in this Symbol: 1394...\n",
      "PROCESSING: CSCO - 51 of 220 symbols...\n",
      "Records in this Symbol: 8779...\n",
      "PROCESSING: CSX - 52 of 220 symbols...\n",
      "Records in this Symbol: 11127...\n",
      "PROCESSING: CTSH - 53 of 220 symbols...\n",
      "Records in this Symbol: 6672...\n",
      "PROCESSING: CVS - 54 of 220 symbols...\n",
      "Records in this Symbol: 13074...\n",
      "PROCESSING: CVX - 55 of 220 symbols...\n",
      "Records in this Symbol: 15853...\n",
      "PROCESSING: C - 56 of 220 symbols...\n",
      "Records in this Symbol: 12097...\n",
      "PROCESSING: DD - 57 of 220 symbols...\n",
      "Records in this Symbol: 13254...\n",
      "PROCESSING: DE - 58 of 220 symbols...\n",
      "Records in this Symbol: 13254...\n",
      "PROCESSING: DGX - 59 of 220 symbols...\n",
      "Records in this Symbol: 7051...\n",
      "PROCESSING: DHR - 60 of 220 symbols...\n",
      "Records in this Symbol: 11594...\n",
      "PROCESSING: DIS - 61 of 220 symbols...\n",
      "Records in this Symbol: 15853...\n",
      "PROCESSING: DOW - 62 of 220 symbols...\n",
      "Records in this Symbol: 1452...\n",
      "PROCESSING: DRI - 63 of 220 symbols...\n",
      "Records in this Symbol: 7459...\n",
      "PROCESSING: DUK - 64 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: EL - 65 of 220 symbols...\n",
      "Records in this Symbol: 7324...\n",
      "PROCESSING: EOG - 66 of 220 symbols...\n",
      "Records in this Symbol: 8873...\n",
      "PROCESSING: EPD - 67 of 220 symbols...\n",
      "Records in this Symbol: 6646...\n",
      "PROCESSING: EQIX - 68 of 220 symbols...\n",
      "Records in this Symbol: 6130...\n",
      "PROCESSING: EQT - 69 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: ETN - 70 of 220 symbols...\n",
      "Records in this Symbol: 13254...\n",
      "PROCESSING: ETSY - 71 of 220 symbols...\n",
      "Records in this Symbol: 2440...\n",
      "PROCESSING: EXC - 72 of 220 symbols...\n",
      "Records in this Symbol: 13025...\n",
      "PROCESSING: EXPE - 73 of 220 symbols...\n",
      "Records in this Symbol: 4890...\n",
      "PROCESSING: FCX - 74 of 220 symbols...\n",
      "Records in this Symbol: 7417...\n",
      "PROCESSING: FDX - 75 of 220 symbols...\n",
      "Records in this Symbol: 11776...\n",
      "PROCESSING: FISV - 76 of 220 symbols...\n",
      "Records in this Symbol: 396...\n",
      "PROCESSING: FIS - 77 of 220 symbols...\n",
      "Records in this Symbol: 5915...\n",
      "PROCESSING: FMC - 78 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: FTNT - 79 of 220 symbols...\n",
      "Records in this Symbol: 3799...\n",
      "PROCESSING: F - 80 of 220 symbols...\n",
      "Records in this Symbol: 13254...\n",
      "PROCESSING: GE - 81 of 220 symbols...\n",
      "Records in this Symbol: 15853...\n",
      "PROCESSING: GILD - 82 of 220 symbols...\n",
      "Records in this Symbol: 8292...\n",
      "PROCESSING: GIS - 83 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: GM - 84 of 220 symbols...\n",
      "Records in this Symbol: 3547...\n",
      "PROCESSING: GOOGL - 85 of 220 symbols...\n",
      "Records in this Symbol: 5122...\n",
      "PROCESSING: GOOG - 86 of 220 symbols...\n",
      "Records in this Symbol: 5122...\n",
      "PROCESSING: GPC - 87 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: GS - 88 of 220 symbols...\n",
      "Records in this Symbol: 6453...\n",
      "PROCESSING: HCA - 89 of 220 symbols...\n",
      "Records in this Symbol: 3471...\n",
      "PROCESSING: HD - 90 of 220 symbols...\n",
      "Records in this Symbol: 10905...\n",
      "PROCESSING: HLT - 91 of 220 symbols...\n",
      "Records in this Symbol: 2776...\n",
      "PROCESSING: HOG - 92 of 220 symbols...\n",
      "Records in this Symbol: 9694...\n",
      "PROCESSING: HPE - 93 of 220 symbols...\n",
      "Records in this Symbol: 2311...\n",
      "PROCESSING: HSBC - 94 of 220 symbols...\n",
      "Records in this Symbol: 6402...\n",
      "PROCESSING: HSY - 95 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: HUM - 96 of 220 symbols...\n",
      "Records in this Symbol: 10835...\n",
      "PROCESSING: IBB - 97 of 220 symbols...\n",
      "Records in this Symbol: 6004...\n",
      "PROCESSING: IBM - 98 of 220 symbols...\n",
      "Records in this Symbol: 15853...\n",
      "PROCESSING: ICE - 99 of 220 symbols...\n",
      "Records in this Symbol: 4807...\n",
      "PROCESSING: INTC - 100 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: ISRG - 101 of 220 symbols...\n",
      "Records in this Symbol: 6169...\n",
      "PROCESSING: JBLU - 102 of 220 symbols...\n",
      "Records in this Symbol: 5715...\n",
      "PROCESSING: JCI - 103 of 220 symbols...\n",
      "Records in this Symbol: 9384...\n",
      "PROCESSING: JNJ - 104 of 220 symbols...\n",
      "Records in this Symbol: 15853...\n",
      "PROCESSING: JPM - 105 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: KHC - 106 of 220 symbols...\n",
      "Records in this Symbol: 2385...\n",
      "PROCESSING: KMB - 107 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: KO - 108 of 220 symbols...\n",
      "Records in this Symbol: 15853...\n",
      "PROCESSING: LLY - 109 of 220 symbols...\n",
      "Records in this Symbol: 13254...\n",
      "PROCESSING: LMT - 110 of 220 symbols...\n",
      "Records in this Symbol: 12097...\n",
      "PROCESSING: LOW - 111 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: LPLA - 112 of 220 symbols...\n",
      "Records in this Symbol: 3547...\n",
      "PROCESSING: LPL - 113 of 220 symbols...\n",
      "Records in this Symbol: 5142...\n",
      "PROCESSING: LRCX - 114 of 220 symbols...\n",
      "Records in this Symbol: 10242...\n",
      "PROCESSING: LULU - 115 of 220 symbols...\n",
      "Records in this Symbol: 4383...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROCESSING: LUV - 116 of 220 symbols...\n",
      "Records in this Symbol: 11340...\n",
      "PROCESSING: LYV - 117 of 220 symbols...\n",
      "Records in this Symbol: 4783...\n",
      "PROCESSING: MA - 118 of 220 symbols...\n",
      "Records in this Symbol: 4677...\n",
      "PROCESSING: MCD - 119 of 220 symbols...\n",
      "Records in this Symbol: 14718...\n",
      "PROCESSING: MCK - 120 of 220 symbols...\n",
      "Records in this Symbol: 7582...\n",
      "PROCESSING: MCO - 121 of 220 symbols...\n",
      "Records in this Symbol: 7590...\n",
      "PROCESSING: MDLZ - 122 of 220 symbols...\n",
      "Records in this Symbol: 5920...\n",
      "PROCESSING: MDT - 123 of 220 symbols...\n",
      "Records in this Symbol: 13025...\n",
      "PROCESSING: MELI - 124 of 220 symbols...\n",
      "Records in this Symbol: 4373...\n",
      "PROCESSING: META - 125 of 220 symbols...\n",
      "Records in this Symbol: 3170...\n",
      "PROCESSING: MET - 126 of 220 symbols...\n",
      "Records in this Symbol: 6219...\n",
      "PROCESSING: MGM - 127 of 220 symbols...\n",
      "Records in this Symbol: 9234...\n",
      "PROCESSING: MMC - 128 of 220 symbols...\n",
      "Records in this Symbol: 13074...\n",
      "PROCESSING: MMM - 129 of 220 symbols...\n",
      "Records in this Symbol: 15853...\n",
      "PROCESSING: MNST - 130 of 220 symbols...\n",
      "Records in this Symbol: 9839...\n",
      "PROCESSING: MO - 131 of 220 symbols...\n",
      "Records in this Symbol: 15853...\n",
      "PROCESSING: MPWR - 132 of 220 symbols...\n",
      "Records in this Symbol: 5057...\n",
      "PROCESSING: MRK - 133 of 220 symbols...\n",
      "Records in this Symbol: 15853...\n",
      "PROCESSING: MSCI - 134 of 220 symbols...\n",
      "Records in this Symbol: 4305...\n",
      "PROCESSING: MSFT - 135 of 220 symbols...\n",
      "Records in this Symbol: 9774...\n",
      "PROCESSING: MS - 136 of 220 symbols...\n",
      "Records in this Symbol: 8017...\n",
      "PROCESSING: MTD - 137 of 220 symbols...\n",
      "Records in this Symbol: 6820...\n",
      "PROCESSING: NAVI - 138 of 220 symbols...\n",
      "Records in this Symbol: 2690...\n",
      "PROCESSING: NDAQ - 139 of 220 symbols...\n",
      "Records in this Symbol: 5660...\n",
      "PROCESSING: NEE - 140 of 220 symbols...\n",
      "Records in this Symbol: 13074...\n",
      "PROCESSING: NEM - 141 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: NFLX - 142 of 220 symbols...\n",
      "Records in this Symbol: 5686...\n",
      "PROCESSING: NKE - 143 of 220 symbols...\n",
      "Records in this Symbol: 11108...\n",
      "PROCESSING: NOC - 144 of 220 symbols...\n",
      "Records in this Symbol: 10835...\n",
      "PROCESSING: NRG - 145 of 220 symbols...\n",
      "Records in this Symbol: 5301...\n",
      "PROCESSING: NSC - 146 of 220 symbols...\n",
      "Records in this Symbol: 10730...\n",
      "PROCESSING: NTRS - 147 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: NVAX - 148 of 220 symbols...\n",
      "Records in this Symbol: 7313...\n",
      "PROCESSING: NVDA - 149 of 220 symbols...\n",
      "Records in this Symbol: 6523...\n",
      "PROCESSING: NXPI - 150 of 220 symbols...\n",
      "Records in this Symbol: 3620...\n",
      "PROCESSING: OKE - 151 of 220 symbols...\n",
      "Records in this Symbol: 11150...\n",
      "PROCESSING: ORCL - 152 of 220 symbols...\n",
      "Records in this Symbol: 9775...\n",
      "PROCESSING: OXY - 153 of 220 symbols...\n",
      "Records in this Symbol: 10835...\n",
      "PROCESSING: PEP - 154 of 220 symbols...\n",
      "Records in this Symbol: 13254...\n",
      "PROCESSING: PFE - 155 of 220 symbols...\n",
      "Records in this Symbol: 13254...\n",
      "PROCESSING: PGR - 156 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: PG - 157 of 220 symbols...\n",
      "Records in this Symbol: 15853...\n",
      "PROCESSING: PHM - 158 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: PLD - 159 of 220 symbols...\n",
      "Records in this Symbol: 6815...\n",
      "PROCESSING: PNC - 160 of 220 symbols...\n",
      "Records in this Symbol: 12381...\n",
      "PROCESSING: PPL - 161 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: PRGO - 162 of 220 symbols...\n",
      "Records in this Symbol: 8316...\n",
      "PROCESSING: PRU - 163 of 220 symbols...\n",
      "Records in this Symbol: 5796...\n",
      "PROCESSING: PSA - 164 of 220 symbols...\n",
      "Records in this Symbol: 11117...\n",
      "PROCESSING: PSX - 165 of 220 symbols...\n",
      "Records in this Symbol: 3196...\n",
      "PROCESSING: PYPL - 166 of 220 symbols...\n",
      "Records in this Symbol: 2385...\n",
      "PROCESSING: QCOM - 167 of 220 symbols...\n",
      "Records in this Symbol: 8318...\n",
      "PROCESSING: QQQ - 168 of 220 symbols...\n",
      "Records in this Symbol: 6491...\n",
      "PROCESSING: RCL - 169 of 220 symbols...\n",
      "Records in this Symbol: 7972...\n",
      "PROCESSING: REGN - 170 of 220 symbols...\n",
      "Records in this Symbol: 8497...\n",
      "PROCESSING: REIT - 171 of 220 symbols...\n",
      "Records in this Symbol: 963...\n",
      "PROCESSING: REXR - 172 of 220 symbols...\n",
      "Records in this Symbol: 2878...\n",
      "PROCESSING: ROST - 173 of 220 symbols...\n",
      "Records in this Symbol: 9923...\n",
      "PROCESSING: RTX - 174 of 220 symbols...\n",
      "Records in this Symbol: 15790...\n",
      "PROCESSING: SBAC - 175 of 220 symbols...\n",
      "Records in this Symbol: 6423...\n",
      "PROCESSING: SBUX - 176 of 220 symbols...\n",
      "Records in this Symbol: 8183...\n",
      "PROCESSING: SHW - 177 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: SLB - 178 of 220 symbols...\n",
      "Records in this Symbol: 10835...\n",
      "PROCESSING: SPGI - 179 of 220 symbols...\n",
      "Records in this Symbol: 13074...\n",
      "PROCESSING: SPG - 180 of 220 symbols...\n",
      "Records in this Symbol: 7812...\n",
      "PROCESSING: SPY - 181 of 220 symbols...\n",
      "Records in this Symbol: 8033...\n",
      "PROCESSING: SQ - 182 of 220 symbols...\n",
      "Records in this Symbol: 2288...\n",
      "PROCESSING: STT - 183 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: STZ - 184 of 220 symbols...\n",
      "Records in this Symbol: 8254...\n",
      "PROCESSING: SWKS - 185 of 220 symbols...\n",
      "Records in this Symbol: 10155...\n",
      "PROCESSING: SYK - 186 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: SYY - 187 of 220 symbols...\n",
      "Records in this Symbol: 13021...\n",
      "PROCESSING: TDG - 188 of 220 symbols...\n",
      "Records in this Symbol: 4727...\n",
      "PROCESSING: TDOC - 189 of 220 symbols...\n",
      "Records in this Symbol: 2388...\n",
      "PROCESSING: TFC - 190 of 220 symbols...\n",
      "Records in this Symbol: 11287...\n",
      "PROCESSING: TGT - 191 of 220 symbols...\n",
      "Records in this Symbol: 13074...\n",
      "PROCESSING: TMO - 192 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: TRV - 193 of 220 symbols...\n",
      "Records in this Symbol: 12381...\n",
      "PROCESSING: TSLA - 194 of 220 symbols...\n",
      "Records in this Symbol: 3647...\n",
      "PROCESSING: TSN - 195 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: TT - 196 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: TXN - 197 of 220 symbols...\n",
      "Records in this Symbol: 13254...\n",
      "PROCESSING: T - 198 of 220 symbols...\n",
      "Records in this Symbol: 10356...\n",
      "PROCESSING: UAL - 199 of 220 symbols...\n",
      "Records in this Symbol: 4753...\n",
      "PROCESSING: UNH - 200 of 220 symbols...\n",
      "Records in this Symbol: 10127...\n",
      "PROCESSING: UPS - 201 of 220 symbols...\n",
      "Records in this Symbol: 6320...\n",
      "PROCESSING: VLO - 202 of 220 symbols...\n",
      "Records in this Symbol: 10834...\n",
      "PROCESSING: VMC - 203 of 220 symbols...\n",
      "Records in this Symbol: 13074...\n",
      "PROCESSING: VNO - 204 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: VRTX - 205 of 220 symbols...\n",
      "Records in this Symbol: 8418...\n",
      "PROCESSING: VTR - 206 of 220 symbols...\n",
      "Records in this Symbol: 6956...\n",
      "PROCESSING: VZ - 207 of 220 symbols...\n",
      "Records in this Symbol: 10356...\n",
      "PROCESSING: V - 208 of 220 symbols...\n",
      "Records in this Symbol: 4221...\n",
      "PROCESSING: WBA - 209 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: WDC - 210 of 220 symbols...\n",
      "Records in this Symbol: 11635...\n",
      "PROCESSING: WELL - 211 of 220 symbols...\n",
      "Records in this Symbol: 11286...\n",
      "PROCESSING: WFC - 212 of 220 symbols...\n",
      "Records in this Symbol: 13254...\n",
      "PROCESSING: WMT - 213 of 220 symbols...\n",
      "Records in this Symbol: 13194...\n",
      "PROCESSING: XEL - 214 of 220 symbols...\n",
      "Records in this Symbol: 13074...\n",
      "PROCESSING: XOM - 215 of 220 symbols...\n",
      "Records in this Symbol: 15853...\n",
      "PROCESSING: YUM - 216 of 220 symbols...\n",
      "Records in this Symbol: 6862...\n",
      "PROCESSING: ZBH - 217 of 220 symbols...\n",
      "Records in this Symbol: 5891...\n",
      "PROCESSING: ZION - 218 of 220 symbols...\n",
      "Records in this Symbol: 11288...\n",
      "PROCESSING: ZM - 219 of 220 symbols...\n",
      "Records in this Symbol: 1431...\n",
      "PROCESSING: ZTS - 220 of 220 symbols...\n",
      "Records in this Symbol: 2994...\n"
     ]
    }
   ],
   "source": [
    "images, tabular_data = tabular_to_image(df, window=3)\n",
    "targets = df['target'].values[2:]  # Align with window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "723e65c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test_img, X_test_tab, y_test, nan_strategy='mean'):\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import classification_report\n",
    "\n",
    "    # Convert all to np arrays\n",
    "    X_test_img = np.asarray(X_test_img, dtype=np.float32)\n",
    "    X_test_tab = np.asarray(X_test_tab, dtype=np.float32)\n",
    "    y_test = np.asarray(y_test)\n",
    "\n",
    "    # Ensure all inputs have same length before continuing\n",
    "    min_len = min(X_test_img.shape[0], X_test_tab.shape[0], y_test.shape[0])\n",
    "    X_test_img = X_test_img[:min_len]\n",
    "    X_test_tab = X_test_tab[:min_len]\n",
    "    y_test = y_test[:min_len]\n",
    "\n",
    "    # Handle NaNs\n",
    "    combined_mask = ~(\n",
    "        np.isnan(X_test_img).any(axis=(1, 2, 3)) |\n",
    "        np.isnan(X_test_tab).any(axis=1)\n",
    "    )\n",
    "\n",
    "    dropped_rows = np.sum(~combined_mask)\n",
    "    if dropped_rows > 0:\n",
    "        print(f\"Warning: {dropped_rows} rows dropped due to NaNs\")\n",
    "        X_test_img = X_test_img[combined_mask]\n",
    "        X_test_tab = X_test_tab[combined_mask]\n",
    "        y_test = y_test[combined_mask]\n",
    "\n",
    "    # Final shape check\n",
    "    assert X_test_img.shape[0] == X_test_tab.shape[0] == y_test.shape[0], \\\n",
    "        f\"Shape mismatch: img={X_test_img.shape}, tab={X_test_tab.shape}, y={y_test.shape}\"\n",
    "\n",
    "    # Predict and evaluate\n",
    "    y_pred = (model.predict([X_test_img, X_test_tab], verbose=0) > 0.5).astype(int)\n",
    "    return classification_report(y_test, y_pred)\n",
    "\n",
    "\n",
    "def build_cnn(input_shape=(6, 3, 1)):\n",
    "    \"\"\"CNN for processing financial 'images'.\"\"\"\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(32, (2, 2), activation='relu')(inputs)\n",
    "    x = MaxPooling2D((1, 1))(x)\n",
    "    x = Flatten()(x)\n",
    "    return Model(inputs, x, name='cnn_branch')\n",
    "\n",
    "def build_tabular_net(input_dim):\n",
    "    \"\"\"Dense network for tabular features.\"\"\"\n",
    "    inputs = Input(shape=(input_dim,))\n",
    "    x = Dense(64, activation='relu')(inputs)\n",
    "    return Model(inputs, x, name='tabular_branch')\n",
    "\n",
    "def build_hybrid_model(cnn_input_shape, tabular_input_dim):\n",
    "    \"\"\"Combine CNN and tabular branches.\"\"\"\n",
    "    # Branches\n",
    "    cnn_model = build_cnn(cnn_input_shape)\n",
    "    tabular_model = build_tabular_net(tabular_input_dim)\n",
    "    \n",
    "    # Combined\n",
    "    combined = Concatenate()([cnn_model.output, tabular_model.output])\n",
    "    z = Dense(32, activation='relu')(combined)\n",
    "    z = Dropout(0.5)(z)\n",
    "    outputs = Dense(1, activation='sigmoid')(z)\n",
    "    \n",
    "    # Full model\n",
    "    return Model(inputs=[cnn_model.input, tabular_model.input], outputs=outputs)\n",
    "\n",
    "# Example usage:\n",
    "# model = build_hybrid_model(cnn_input_shape=(7, 3, 1), tabular_input_dim=2)\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def handle_nans(array, strategy='mean'):\n",
    "    \"\"\"Handle NaN values in numpy arrays with specified strategy.\"\"\"\n",
    "    if not np.isnan(array).any():\n",
    "        return array\n",
    "        \n",
    "    print(f\"Warning: NaN values detected ({np.isnan(array).sum()} elements)\")\n",
    "    \n",
    "    if strategy == 'mean':\n",
    "        fill_value = np.nanmean(array)\n",
    "    elif strategy == 'median':\n",
    "        fill_value = np.nanmedian(array)\n",
    "    elif strategy == 'zero':\n",
    "        fill_value = 0\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown strategy: {strategy}\")\n",
    "        \n",
    "    return np.nan_to_num(array, nan=fill_value)\n",
    "\n",
    "def train_model(model, X_train_img, X_train_tab, y_train, epochs=10, batch_size=32, \n",
    "               nan_strategy='mean', verbose=1):\n",
    "    \"\"\"Robust training function with NaN handling and validation.\n",
    "    \n",
    "    Args:\n",
    "        model: Compiled Keras model\n",
    "        X_train_img: Image data (n_samples, height, width, channels)\n",
    "        X_train_tab: Tabular data (n_samples, n_features)\n",
    "        y_train: Target values\n",
    "        epochs: Training epochs\n",
    "        batch_size: Batch size\n",
    "        nan_strategy: How to handle NaNs ('mean', 'median', 'zero', or 'error')\n",
    "        verbose: Verbosity level\n",
    "        \n",
    "    Returns:\n",
    "        Training history\n",
    "    \"\"\"\n",
    "    # Convert inputs to numpy arrays\n",
    "    X_train_img = np.asarray(X_train_img, dtype='float32')\n",
    "    X_train_tab = np.asarray(X_train_tab, dtype='float32')\n",
    "    y_train = np.asarray(y_train)\n",
    "    \n",
    "    # Handle NaN values\n",
    "    if nan_strategy == 'error':\n",
    "        for name, arr in [('Image data', X_train_img), \n",
    "                         ('Tabular data', X_train_tab),\n",
    "                         ('Target values', y_train)]:\n",
    "            if np.isnan(arr).any():\n",
    "                raise ValueError(f\"{name} contains {np.isnan(arr).sum()} NaN values\")\n",
    "    else:\n",
    "        X_train_img = handle_nans(X_train_img, nan_strategy)\n",
    "        X_train_tab = handle_nans(X_train_tab, nan_strategy)\n",
    "        y_train = handle_nans(y_train, nan_strategy)\n",
    "    \n",
    "    # Validate shapes\n",
    "    if X_train_img.ndim != 4:\n",
    "        raise ValueError(f\"Image data must be 4D (got {X_train_img.shape})\")\n",
    "    if X_train_tab.ndim != 2:\n",
    "        raise ValueError(f\"Tabular data must be 2D (got {X_train_tab.shape})\")\n",
    "    \n",
    "    # Prepare targets\n",
    "    if y_train.ndim == 1 or y_train.shape[1] == 1:\n",
    "        if len(np.unique(y_train)) > 2:\n",
    "            y_train = to_categorical(y_train)\n",
    "        else:\n",
    "            y_train = y_train.astype('float32')\n",
    "    \n",
    "    # Compile and train\n",
    "    model.compile(optimizer='adam',\n",
    "                 loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(\n",
    "        [X_train_img, X_train_tab],\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=0.1,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcd0845",
   "metadata": {},
   "source": [
    "# Saving Data after Image Generation for Future Use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "86cfb07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# --- Save data to thesis_data directory ---\n",
    "os.makedirs(\"thesis_data\", exist_ok=True)\n",
    "np.save(\"thesis_data/images.npy\", images)\n",
    "np.save(\"thesis_data/tabular_data.npy\", tabular_data)\n",
    "np.save(\"thesis_data/targets.npy\", targets)\n",
    "\n",
    "#np.save(\"thesis_data/images.npy\", images.astype(np.float64))  # Save as float64 to ensure precision\n",
    "#np.save(\"thesis_data/tabular_data.npy\", tabular_data.astype(np.float64))\n",
    "#np.save(\"thesis_data/targets.npy\", targets.astype(np.float64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6ba66168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images match: False\n",
      "Tabular data match: True\n",
      "Targets match: True\n",
      "Images approximately match: False\n"
     ]
    }
   ],
   "source": [
    "images_loaded = np.load(\"thesis_data/images.npy\", allow_pickle=True)\n",
    "tabular_data_loaded = np.load(\"thesis_data/tabular_data.npy\", allow_pickle=True)\n",
    "targets_loaded = np.load(\"thesis_data/targets.npy\", allow_pickle=True)\n",
    "\n",
    "\n",
    "# Compare to ensure data integrity\n",
    "print(\"Images match:\", np.array_equal(images, images_loaded))\n",
    "print(\"Tabular data match:\", np.array_equal(tabular_data, tabular_data_loaded))\n",
    "print(\"Targets match:\", np.array_equal(targets, targets_loaded))\n",
    "print(\"Images approximately match:\", np.allclose(images, images_loaded))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd3d218",
   "metadata": {},
   "source": [
    "# Testing And Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5912ba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def train_test_split_ts(images, tabular_data, targets, test_size=0.2):\n",
    "    \"\"\"Time-series aware split (no shuffling).\"\"\"\n",
    "    split_idx = int(len(images) * (1 - test_size))\n",
    "    X_train_img, X_test_img = images[:split_idx], images[split_idx:]\n",
    "    X_train_tab, X_test_tab = tabular_data[:split_idx], tabular_data[split_idx:]\n",
    "    y_train, y_test = targets[:split_idx], targets[split_idx:]\n",
    "    return (X_train_img, X_train_tab, y_train), (X_test_img, X_test_tab, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "b055a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_img, X_train_tab, y_train), (X_test_img, X_test_tab, y_test) = \\\n",
    "    train_test_split_ts(images, tabular_data, targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f43005ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_hybrid_model(cnn_input_shape=(6, 3, 1), tabular_input_dim=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cb944ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: NaN values detected (14091 elements)\n",
      "Epoch 1/10\n",
      "44188/44188 [==============================] - 142s 3ms/step - loss: 0.6588 - accuracy: 0.6306 - val_loss: 0.6593 - val_accuracy: 0.6297\n",
      "Epoch 2/10\n",
      "44188/44188 [==============================] - 143s 3ms/step - loss: 0.6586 - accuracy: 0.6306 - val_loss: 0.6591 - val_accuracy: 0.6297\n",
      "Epoch 3/10\n",
      "44188/44188 [==============================] - 137s 3ms/step - loss: 0.6586 - accuracy: 0.6306 - val_loss: 0.6592 - val_accuracy: 0.6297\n",
      "Epoch 4/10\n",
      "44188/44188 [==============================] - 170s 4ms/step - loss: 0.6586 - accuracy: 0.6306 - val_loss: 0.6591 - val_accuracy: 0.6297\n",
      "Epoch 5/10\n",
      "44188/44188 [==============================] - 142s 3ms/step - loss: 0.6586 - accuracy: 0.6306 - val_loss: 0.6591 - val_accuracy: 0.6297\n",
      "Epoch 6/10\n",
      "44188/44188 [==============================] - 139s 3ms/step - loss: 0.6586 - accuracy: 0.6306 - val_loss: 0.6592 - val_accuracy: 0.6297\n",
      "Epoch 7/10\n",
      "44188/44188 [==============================] - 140s 3ms/step - loss: 0.6586 - accuracy: 0.6306 - val_loss: 0.6591 - val_accuracy: 0.6297\n",
      "Epoch 8/10\n",
      "44188/44188 [==============================] - 147s 3ms/step - loss: 0.6586 - accuracy: 0.6306 - val_loss: 0.6591 - val_accuracy: 0.6297\n",
      "Epoch 9/10\n",
      "44188/44188 [==============================] - 156s 4ms/step - loss: 0.6586 - accuracy: 0.6306 - val_loss: 0.6591 - val_accuracy: 0.6297\n",
      "Epoch 10/10\n",
      "44188/44188 [==============================] - 141s 3ms/step - loss: 0.6586 - accuracy: 0.6306 - val_loss: 0.6592 - val_accuracy: 0.6297\n"
     ]
    }
   ],
   "source": [
    "history = train_model(model, X_train_img, X_train_tab, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6006f3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 1025 rows dropped due to NaNs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\musha\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      1.00      0.78    250509\n",
      "           1       0.00      0.00      0.00    141244\n",
      "\n",
      "    accuracy                           0.64    391753\n",
      "   macro avg       0.32      0.50      0.39    391753\n",
      "weighted avg       0.41      0.64      0.50    391753\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\musha\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\musha\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_model(model, X_test_img, X_test_tab, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
